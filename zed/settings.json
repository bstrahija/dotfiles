{
  "agent": {
    "default_model": {
      "provider": "copilot_chat",
      "model": "claude-sonnet-4"
    },
    "dock": "left"
  },
  "autosave": "on_focus_change",
  "base_keymap": "VSCode",
  "buffer_font_family": "DankMono Nerd Font",
  "buffer_font_size": 15,
  "buffer_line_height": { "custom": 2.4 },
  "cursor_blink": false,
  "features": {
    "edit_prediction_provider": "copilot"
  },
  "file_scan_exclusions": ["_model_helpers.php"],
  "file_types": {
    "Blade": ["*.blade.php"]
  },
  "icon_theme": "Catppuccin Mocha",
  "indent_guides": {
    "enabled": true
  },
  // Uncomment below to use local AI with Ollama, refer https://zed.dev/docs/language-model-integration?highlight=ollama#using-ollama-on-macos
  // "assistant": {
  //   "default_model": {
  //     "provider": "ollama",
  //     "model": "llama3.1:latest"
  //   },
  //   "version": "2",
  //   "provider": null
  // },
  "language_models": {
    "ollama": {
      "api_url": "http://localhost:11434"
    }
  },
  "languages": {
    "PHP": {
      "language_servers": [
        "!phpactor",
        "intelephense",
        "!phptools",
        "phpdocs",
        "..."
      ],
      "formatter": "language_server",
      "prettier": {
        "allowed": true,
        "plugins": ["@prettier/plugin-php", "@prettier/plugin-blade"],
        "parser": "php"
      }
    }
  },
  "lsp": {
    "intelephense": {
      "initialization_options": {
        "licenceKey": "~/.config/intelephense/licence.txt"
      },
      "settings": {
        "environment": {
          "phpVersion": "8.4.0"
        }
      }
    }
  },
  "project_panel": {
    "dock": "right",
    "default_width": 360
  },
  "relative_line_numbers": true,
  "show_whitespaces": "selection",
  "tabs": {
    "file_icons": false,
    "git_status": true
  },
  "theme": {
    "mode": "system",
    "light": "One Light",
    "dark": "Everforest Dark Medium"
  },
  "toolbar": {
    "breadcrumbs": false,
    "quick_actions": false
  },
  "ui_font_size": 15,
  "vim_mode": true
}
